{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "import wandb\n",
    "os.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "from xgboost import XGBRegressor as XGB\n",
    "import lightgbm\n",
    "from lightgbm import LGBMRegressor as LGB\n",
    "from catboost import CatBoostRegressor as CB\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import VotingClassifier, StackingClassifier, RandomForestRegressor, ExtraTreesRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import PowerTransformer, FunctionTransformer, StandardScaler, OneHotEncoder\n",
    "\n",
    "from sklearn.metrics import mean_squared_log_error, mean_squared_error\n",
    "\n",
    "import functools\n",
    "rmse = functools.partial(mean_squared_error, squared=False)\n",
    "rmsle = functools.partial(mean_squared_log_error, squared=False)\n",
    "\n",
    "\n",
    "SEED=42\n",
    "\n",
    "from src.styles import set_styles, TXT_ACC, TXT_RESET\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# ---- REPRODICIBILITY ------------------------------------------------\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# ---- PANDAS ---------------------------------------------------------\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.display.float_format = '{:,.4f}'.format\n",
    "\n",
    "\n",
    "set_styles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    path_train = 'data/train.csv'\n",
    "    path_test = 'data/test.csv'\n",
    "    path_original = 'data/abalone.csv'\n",
    "    target = 'Rings'\n",
    "    project = 'PGs04e04'\n",
    "    num_folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper_sex = {'I':0, 'F':1, 'M':2}\n",
    "\n",
    "df_train = pd.read_csv(CFG.path_train).drop('id', axis=1)\n",
    "df_train['Sex'] = df_train['Sex'].map(mapper_sex)\n",
    "\n",
    "# df_test = pd.read_csv(CFG.path_test).drop('id', axis=1)\n",
    "# df_test['Sex'] = df_test['Sex'].map(mapper_sex)\n",
    "\n",
    "df_original = pd.read_csv(CFG.path_original)\n",
    "df_original['Sex'] = df_original['Sex'].map(mapper_sex)\n",
    "df_original = df_original.rename(columns={'Shucked weight': 'Whole weight.1', 'Viscera weight': 'Whole weight.2'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lgb_params_grid():\n",
    "    return {\n",
    "        'max_depth':         {'min': 3,    'max': 10},\n",
    "        'n_estimators':      {'min': 100,  'max': 1000},\n",
    "        'learning_rate':     {'min': 0.01, 'max': 0.2},\n",
    "        'reg_alpha':         {'min':0.0,   'max': 100.},\n",
    "        'reg_lambda':        {'min':0.0,   'max': 100.},\n",
    "        'subsample':         {'values': np.arange(0.5, 1.01, 0.1).tolist()},\n",
    "        'boosting':          {'value': 'gbdt'},\n",
    "        'random_state':      {'value': SEED},\n",
    "        'objective':         {'value': 'regression'},\n",
    "        'device':            {'value': 'gpu'},\n",
    "     }\n",
    "\n",
    "\n",
    "# def get_lgb_params_grid():\n",
    "#     return {\n",
    "#         'num_leaves':        {'min': 5,    'max': 500},\n",
    "#         'n_estimators':      {'min': 100,  'max': 1000},\n",
    "#         'min_child_samples': {'min': 10,   'max': 300},\n",
    "#         'learning_rate':     {'min': 0.01, 'max': 0.2},\n",
    "#         'reg_alpha':         {'min':0.0,   'max': 100.},\n",
    "#         'reg_lambda':        {'min':0.0,   'max': 100.},\n",
    "#         'subsample':         {'values': np.arange(0.5, 1.01, 0.1).tolist()},\n",
    "#         'boosting':          {'value': 'gbdt'},\n",
    "#         'random_state':      {'value': SEED},\n",
    "#         'objective':         {'value': 'regression'},\n",
    "#         'device':            {'value': 'gpu'},\n",
    "#      }\n",
    "\n",
    "\n",
    "def get_catboost_params_grid():\n",
    "    return {\n",
    "        'depth':             {'min': 3,    'max': 10},\n",
    "        'iterations':        {'min': 100,  'max': 1000},\n",
    "        'min_data_in_leaf':  {'min': 10,   'max': 300},\n",
    "        'learning_rate':     {'min': 0.01, 'max': 0.2},\n",
    "        'l2_leaf_reg':       {'min':0.0,   'max': 100.},\n",
    "        'subsample':         {'values': np.arange(0.5, 1.01, 0.1).tolist()},\n",
    "        'random_state':      {'value': SEED},\n",
    "        'loss_function':     {'value': 'RMSE'},\n",
    "        'verbose':           {'value': 0},\n",
    "    }\n",
    "\n",
    "\n",
    "def get_xgb_params_grid(use_log=False):\n",
    "    return {\n",
    "            'max_depth':         {'min': 3,    'max': 10},\n",
    "            'n_estimators':      {'min': 100,  'max': 1000},\n",
    "            'learning_rate':     {'min': 0.01, 'max': 0.2},\n",
    "            'alpha':             {'min':0.0,   'max': 100.},\n",
    "            'lambda':            {'min':0.0,   'max': 100.},\n",
    "            'subsample':         {'values': np.arange(0.5, 1.01, 0.1).tolist()},\n",
    "            'booster':           {'value': 'gbtree'},\n",
    "            'random_state':      {'value': SEED},\n",
    "            'objective':         {'value': 'reg:squarederror' if not use_log else 'reg:squaredlogerror'},\n",
    "            'tree_method':       {'value': 'gpu_hist'},\n",
    "            }\n",
    "\n",
    "\n",
    "def get_config(name, param_grid):\n",
    "    return {\n",
    "        'name': f'sweep_{name}',\n",
    "        'method': 'bayes',\n",
    "        'metric': {'goal': 'minimize', 'name': 'score_mean'},\n",
    "        'parameters': param_grid,\n",
    "        }\n",
    "\n",
    "\n",
    "def score_cv(X, cv, model, df_original=None):\n",
    "    scores = []\n",
    "    for fold, (idx_train, idx_val) in enumerate(cv.split(X, X[CFG.target])):\n",
    "        X_train = X.loc[idx_train]\n",
    "        if df_original is not None:\n",
    "            X_train = pd.concat([X_train, df_original], axis=0)\n",
    "        Y_train = X_train.pop(CFG.target)\n",
    "        X_val = X.loc[idx_val]\n",
    "        Y_val = X_val.pop(CFG.target)\n",
    "        \n",
    "        model.fit(X_train, Y_train)\n",
    "        preds = model.predict(X_val).clip(1., 29.)\n",
    "        score = rmsle(Y_val, preds)\n",
    "        scores.append(score)\n",
    "        \n",
    "    return np.array(scores)\n",
    "\n",
    "\n",
    "def objective_catboost():\n",
    "    wandb.init(project=CFG.project)\n",
    "    \n",
    "    model = TransformedTargetRegressor(\n",
    "                    CB(**wandb.config),\n",
    "                    func=np.log1p, \n",
    "                    inverse_func=np.expm1)\n",
    "    scores = score_cv(X, cv, model, df_original)\n",
    "\n",
    "    wandb.log({f'score_{i}': sc for i, sc in enumerate(scores)})\n",
    "    wandb.log({'score_mean': scores.mean()})    \n",
    "\n",
    "\n",
    "\n",
    "def objective_lgb():\n",
    "    wandb.init(project=CFG.project)\n",
    "    \n",
    "    model = TransformedTargetRegressor(\n",
    "                    LGB(**wandb.config, num_leaves=2**wandb.config['max_depth'] - 1),\n",
    "                    func=np.log1p, \n",
    "                    inverse_func=np.expm1)\n",
    "    scores = score_cv(X, cv, model, df_original)\n",
    "\n",
    "    wandb.log({f'score_{i}': sc for i, sc in enumerate(scores)})\n",
    "    wandb.log({'score_mean': scores.mean()})    \n",
    "\n",
    "\n",
    "def objective_xgb():\n",
    "    wandb.init(project=CFG.project)\n",
    "    \n",
    "    model = TransformedTargetRegressor(\n",
    "                    XGB(**wandb.config),\n",
    "                    func=np.log1p, \n",
    "                    inverse_func=np.expm1)\n",
    "    scores = score_cv(X, cv, model)\n",
    "\n",
    "    wandb.log({f'score_{i}': sc for i, sc in enumerate(scores)})\n",
    "    wandb.log({'score_mean': scores.mean()})    \n",
    "\n",
    "\n",
    "\n",
    "def objective_xgb_log():\n",
    "    wandb.init(project=CFG.project)\n",
    "    \n",
    "    model = XGB(**wandb.config)\n",
    "    scores = score_cv(X, cv, model)\n",
    "\n",
    "    wandb.log({f'score_{i}': sc for i, sc in enumerate(scores)})\n",
    "    wandb.log({'score_mean': scores.mean()})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = ''\n",
    "wandb.login(key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 200\n",
    "experiments = (\n",
    "               # ('catboost_with_orig',     get_config('catboost_with_orig', get_catboost_params_grid()),           objective_catboost,   N),\n",
    "               ('lgb_with_orig',          get_config('lgb_with_orig',      get_lgb_params_grid()),                objective_lgb,        N),\n",
    "            #    ('xgb',     get_config('xgb',      get_xgb_params_grid(use_log=False)),   objective_xgb,      N),\n",
    "            #    ('xgb_log', get_config('xgb_log',  get_xgb_params_grid(use_log=True)),    objective_xgb_log,  N),\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train\n",
    "cv = StratifiedKFold(n_splits=CFG.num_folds, shuffle=True, random_state=SEED)\n",
    "\n",
    "for label, config, objective, count in experiments:\n",
    "\n",
    "    print(f'{TXT_ACC} {label} {TXT_RESET}')\n",
    "    \n",
    "    try:\n",
    "        sweep_id = wandb.sweep(sweep=config, project=CFG.project)            \n",
    "        wandb.agent(sweep_id, function=objective, count=count)        \n",
    "    except:\n",
    "        print('Something went wrong')\n",
    "    finally:\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load sweep results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sweep_results(wandb_api, sweep_id):\n",
    "    print(sweep_id)\n",
    "    sw = wandb_api.sweep(f\"nasonova-alexandra/{CFG.project}/{sweep_id}\")\n",
    "\n",
    "    columns_metrics = [f'score_{i}' for i in range(CFG.num_folds)]\n",
    "\n",
    "    runs = [(run.history()[columns_metrics].values[0], run.config) for run in sw.runs]\n",
    "    \n",
    "    configs = [r[1] for r in runs]\n",
    "    scores  = [r[0] for r in runs]\n",
    "    df = pd.DataFrame(configs)\n",
    "    df[columns_metrics] = scores\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_api = wandb.Api()\n",
    "sweeps = (  ('sweep_catboost_with_original', 'hrkn47d1'),\n",
    "            ('sweep_lgb_with_original',      '24wrt6fu'))\n",
    "for path_save, sweep_id in sweeps:\n",
    "    df = get_sweep_results(wandb_api, sweep_id)\n",
    "    df.to_csv(path_save+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get best parameters for each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[38;5;254m\u001b[48;5;240m sweep_catboost_with_original   fold 0 \u001b[0m\n",
      "depth                    7\n",
      "verbose                  0\n",
      "subsample           0.8000\n",
      "iterations             974\n",
      "l2_leaf_reg        20.6278\n",
      "random_state            42\n",
      "learning_rate       0.1444\n",
      "loss_function         RMSE\n",
      "min_data_in_leaf       103\n",
      "score_0             0.1482\n",
      "score_1             0.1492\n",
      "score_2             0.1495\n",
      "score_3             0.1492\n",
      "score_4             0.1474\n",
      "score_mean          0.1487\n",
      "Name: 51, dtype: object\n",
      "\u001b[1m\u001b[38;5;254m\u001b[48;5;240m sweep_catboost_with_original   fold 1 \u001b[0m\n",
      "depth                    7\n",
      "verbose                  0\n",
      "subsample           0.5000\n",
      "iterations             994\n",
      "l2_leaf_reg        78.0573\n",
      "random_state            42\n",
      "learning_rate       0.1892\n",
      "loss_function         RMSE\n",
      "min_data_in_leaf        24\n",
      "score_0             0.1483\n",
      "score_1             0.1489\n",
      "score_2             0.1494\n",
      "score_3             0.1494\n",
      "score_4             0.1475\n",
      "score_mean          0.1487\n",
      "Name: 151, dtype: object\n",
      "\u001b[1m\u001b[38;5;254m\u001b[48;5;240m sweep_catboost_with_original   fold 2 \u001b[0m\n",
      "depth                    7\n",
      "verbose                  0\n",
      "subsample           0.5000\n",
      "iterations             995\n",
      "l2_leaf_reg        35.7533\n",
      "random_state            42\n",
      "learning_rate       0.1531\n",
      "loss_function         RMSE\n",
      "min_data_in_leaf       294\n",
      "score_0             0.1483\n",
      "score_1             0.1492\n",
      "score_2             0.1493\n",
      "score_3             0.1493\n",
      "score_4             0.1474\n",
      "score_mean          0.1487\n",
      "Name: 134, dtype: object\n",
      "\u001b[1m\u001b[38;5;254m\u001b[48;5;240m sweep_catboost_with_original   fold 3 \u001b[0m\n",
      "depth                    7\n",
      "verbose                  0\n",
      "subsample           0.7000\n",
      "iterations             951\n",
      "l2_leaf_reg        16.2111\n",
      "random_state            42\n",
      "learning_rate       0.1465\n",
      "loss_function         RMSE\n",
      "min_data_in_leaf       185\n",
      "score_0             0.1484\n",
      "score_1             0.1490\n",
      "score_2             0.1496\n",
      "score_3             0.1491\n",
      "score_4             0.1474\n",
      "score_mean          0.1487\n",
      "Name: 24, dtype: object\n",
      "\u001b[1m\u001b[38;5;254m\u001b[48;5;240m sweep_catboost_with_original   fold 4 \u001b[0m\n",
      "depth                    6\n",
      "verbose                  0\n",
      "subsample           0.7000\n",
      "iterations             879\n",
      "l2_leaf_reg        42.1457\n",
      "random_state            42\n",
      "learning_rate       0.1933\n",
      "loss_function         RMSE\n",
      "min_data_in_leaf       268\n",
      "score_0             0.1484\n",
      "score_1             0.1493\n",
      "score_2             0.1498\n",
      "score_3             0.1493\n",
      "score_4             0.1471\n",
      "score_mean          0.1488\n",
      "Name: 65, dtype: object\n",
      "\u001b[1m\u001b[38;5;254m\u001b[48;5;240m sweep_catboost_with_original \u001b[0m\n",
      "[{'depth': 7, 'verbose': 0, 'subsample': 0.7999999999999999, 'iterations': 974, 'l2_leaf_reg': 20.62778627087155, 'random_state': 42, 'learning_rate': 0.1444264894797429, 'loss_function': 'RMSE', 'min_data_in_leaf': 103}, {'depth': 7, 'verbose': 0, 'subsample': 0.5, 'iterations': 994, 'l2_leaf_reg': 78.05729168782912, 'random_state': 42, 'learning_rate': 0.1892106979772809, 'loss_function': 'RMSE', 'min_data_in_leaf': 24}, {'depth': 7, 'verbose': 0, 'subsample': 0.5, 'iterations': 995, 'l2_leaf_reg': 35.753302241413856, 'random_state': 42, 'learning_rate': 0.1530667105689769, 'loss_function': 'RMSE', 'min_data_in_leaf': 294}, {'depth': 7, 'verbose': 0, 'subsample': 0.7, 'iterations': 951, 'l2_leaf_reg': 16.21107573604743, 'random_state': 42, 'learning_rate': 0.1465196325434651, 'loss_function': 'RMSE', 'min_data_in_leaf': 185}, {'depth': 6, 'verbose': 0, 'subsample': 0.7, 'iterations': 879, 'l2_leaf_reg': 42.145665562690425, 'random_state': 42, 'learning_rate': 0.1932933415779507, 'loss_function': 'RMSE', 'min_data_in_leaf': 268}]\n",
      "\u001b[1m\u001b[38;5;254m\u001b[48;5;240m sweep_lgb_with_original   fold 0 \u001b[0m\n",
      "device                  gpu\n",
      "boosting               gbdt\n",
      "max_depth                 5\n",
      "objective        regression\n",
      "reg_alpha            2.7903\n",
      "subsample            0.9000\n",
      "reg_lambda          98.8620\n",
      "n_estimators            640\n",
      "random_state             42\n",
      "learning_rate        0.1765\n",
      "score_0              0.1476\n",
      "score_1              0.1483\n",
      "score_2              0.1488\n",
      "score_3              0.1490\n",
      "score_4              0.1470\n",
      "score_mean           0.1482\n",
      "Name: 104, dtype: object\n",
      "\u001b[1m\u001b[38;5;254m\u001b[48;5;240m sweep_lgb_with_original   fold 1 \u001b[0m\n",
      "device                  gpu\n",
      "boosting               gbdt\n",
      "max_depth                 5\n",
      "objective        regression\n",
      "reg_alpha            2.2056\n",
      "subsample            0.9000\n",
      "reg_lambda          93.7119\n",
      "n_estimators            722\n",
      "random_state             42\n",
      "learning_rate        0.1797\n",
      "score_0              0.1480\n",
      "score_1              0.1483\n",
      "score_2              0.1490\n",
      "score_3              0.1489\n",
      "score_4              0.1470\n",
      "score_mean           0.1482\n",
      "Name: 66, dtype: object\n",
      "\u001b[1m\u001b[38;5;254m\u001b[48;5;240m sweep_lgb_with_original   fold 2 \u001b[0m\n",
      "device                  gpu\n",
      "boosting               gbdt\n",
      "max_depth                 5\n",
      "objective        regression\n",
      "reg_alpha            0.9231\n",
      "subsample            1.0000\n",
      "reg_lambda          99.2165\n",
      "n_estimators            579\n",
      "random_state             42\n",
      "learning_rate        0.1454\n",
      "score_0              0.1479\n",
      "score_1              0.1484\n",
      "score_2              0.1487\n",
      "score_3              0.1488\n",
      "score_4              0.1468\n",
      "score_mean           0.1481\n",
      "Name: 50, dtype: object\n",
      "\u001b[1m\u001b[38;5;254m\u001b[48;5;240m sweep_lgb_with_original   fold 3 \u001b[0m\n",
      "device                  gpu\n",
      "boosting               gbdt\n",
      "max_depth                 5\n",
      "objective        regression\n",
      "reg_alpha            0.9231\n",
      "subsample            1.0000\n",
      "reg_lambda          99.2165\n",
      "n_estimators            579\n",
      "random_state             42\n",
      "learning_rate        0.1454\n",
      "score_0              0.1479\n",
      "score_1              0.1484\n",
      "score_2              0.1487\n",
      "score_3              0.1488\n",
      "score_4              0.1468\n",
      "score_mean           0.1481\n",
      "Name: 50, dtype: object\n",
      "\u001b[1m\u001b[38;5;254m\u001b[48;5;240m sweep_lgb_with_original   fold 4 \u001b[0m\n",
      "device                  gpu\n",
      "boosting               gbdt\n",
      "max_depth                 5\n",
      "objective        regression\n",
      "reg_alpha            1.2229\n",
      "subsample            1.0000\n",
      "reg_lambda          93.6596\n",
      "n_estimators            596\n",
      "random_state             42\n",
      "learning_rate        0.1330\n",
      "score_0              0.1477\n",
      "score_1              0.1484\n",
      "score_2              0.1488\n",
      "score_3              0.1490\n",
      "score_4              0.1467\n",
      "score_mean           0.1481\n",
      "Name: 83, dtype: object\n",
      "\u001b[1m\u001b[38;5;254m\u001b[48;5;240m sweep_lgb_with_original \u001b[0m\n",
      "[{'device': 'gpu', 'boosting': 'gbdt', 'max_depth': 5, 'objective': 'regression', 'reg_alpha': 2.790271401831723, 'subsample': 0.8999999999999999, 'reg_lambda': 98.86202121297616, 'n_estimators': 640, 'random_state': 42, 'learning_rate': 0.1765129798011447}, {'device': 'gpu', 'boosting': 'gbdt', 'max_depth': 5, 'objective': 'regression', 'reg_alpha': 2.2056343316599225, 'subsample': 0.8999999999999999, 'reg_lambda': 93.71192401252894, 'n_estimators': 722, 'random_state': 42, 'learning_rate': 0.1797135568956882}, {'device': 'gpu', 'boosting': 'gbdt', 'max_depth': 5, 'objective': 'regression', 'reg_alpha': 0.9230695630977448, 'subsample': 1.0, 'reg_lambda': 99.21650396828215, 'n_estimators': 579, 'random_state': 42, 'learning_rate': 0.1453865026227929}, {'device': 'gpu', 'boosting': 'gbdt', 'max_depth': 5, 'objective': 'regression', 'reg_alpha': 0.9230695630977448, 'subsample': 1.0, 'reg_lambda': 99.21650396828215, 'n_estimators': 579, 'random_state': 42, 'learning_rate': 0.1453865026227929}, {'device': 'gpu', 'boosting': 'gbdt', 'max_depth': 5, 'objective': 'regression', 'reg_alpha': 1.2229327339862928, 'subsample': 1.0, 'reg_lambda': 93.65955291434508, 'n_estimators': 596, 'random_state': 42, 'learning_rate': 0.1329652767998142}]\n"
     ]
    }
   ],
   "source": [
    "columns_metrics = [f'score_{i}' for i in range(5)]\n",
    "for label, _ in sweeps:\n",
    "    df = pd.read_csv(label+'.csv')\n",
    "    df['score_mean'] = np.mean(df[columns_metrics], axis=1)\n",
    "    best_vals = []\n",
    "    for fold in range(CFG.num_folds):\n",
    "        print(f'{TXT_ACC} {label}   fold {fold} {TXT_RESET}')\n",
    "        print(df.sort_values(f'score_{fold}').iloc[0,:])\n",
    "        best_vals_fold = df.sort_values(f'score_{fold}').iloc[0,:-6].to_dict()\n",
    "        best_vals.append(best_vals_fold)\n",
    "    \n",
    "    print(f'{TXT_ACC} {label} {TXT_RESET}')\n",
    "    print(best_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
