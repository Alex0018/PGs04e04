{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1fc90afa2f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.nn_tabular_models.node_model import NODEModel\n",
    "from src.nn_tabular_models.saint_model import SAINTModel\n",
    "from src.nn_tabular_models.tabpfn_model import TABPFNModel\n",
    "from src.nn_tabular_models.tab_transformer_model import TabTransformerModel\n",
    "from src.nn_tabular_models.autoint_model import AutoIntModel\n",
    "from src.nn_tabular_models.ft_transformer_model import FTTransformerModel\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "\n",
    "from src.abalone_dataset import AbaloneDataset\n",
    "from src.training_loop import training_loop\n",
    "from src.styles import TXT_ACC, TXT_RESET\n",
    "\n",
    "from src.tabular_nn_tuner import TabularNNTuner\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "SEED=42\n",
    "\n",
    "PROJECT = 'PGs04e04'\n",
    "\n",
    "# ---- REPRODICIBILITY ------------------------------------------------\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    path_train = 'data/train.csv'\n",
    "    path_test = 'data/test.csv'\n",
    "    path_original = 'data/abalone.csv'\n",
    "    target = 'Rings'\n",
    "    project = PROJECT\n",
    "    num_folds=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Whole weight.1</th>\n",
       "      <th>Whole weight.2</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.7715</td>\n",
       "      <td>0.3285</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.145</td>\n",
       "      <td>1.1300</td>\n",
       "      <td>0.4580</td>\n",
       "      <td>0.2765</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.9145</td>\n",
       "      <td>0.3755</td>\n",
       "      <td>0.2055</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.7820</td>\n",
       "      <td>0.3695</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.1975</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90610</th>\n",
       "      <td>M</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.1585</td>\n",
       "      <td>0.0685</td>\n",
       "      <td>0.0370</td>\n",
       "      <td>0.0450</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90611</th>\n",
       "      <td>M</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.8790</td>\n",
       "      <td>0.3865</td>\n",
       "      <td>0.1815</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90612</th>\n",
       "      <td>I</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1510</td>\n",
       "      <td>0.0785</td>\n",
       "      <td>0.0815</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90613</th>\n",
       "      <td>I</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.0980</td>\n",
       "      <td>0.0490</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90614</th>\n",
       "      <td>I</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.3455</td>\n",
       "      <td>0.1525</td>\n",
       "      <td>0.0785</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90615 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex  Length  Diameter  Height  Whole weight  Whole weight.1  \\\n",
       "0       F   0.550     0.430   0.150        0.7715          0.3285   \n",
       "1       F   0.630     0.490   0.145        1.1300          0.4580   \n",
       "2       I   0.160     0.110   0.025        0.0210          0.0055   \n",
       "3       M   0.595     0.475   0.150        0.9145          0.3755   \n",
       "4       I   0.555     0.425   0.130        0.7820          0.3695   \n",
       "...    ..     ...       ...     ...           ...             ...   \n",
       "90610   M   0.335     0.235   0.075        0.1585          0.0685   \n",
       "90611   M   0.555     0.425   0.150        0.8790          0.3865   \n",
       "90612   I   0.435     0.330   0.095        0.3215          0.1510   \n",
       "90613   I   0.345     0.270   0.075        0.2000          0.0980   \n",
       "90614   I   0.425     0.325   0.100        0.3455          0.1525   \n",
       "\n",
       "       Whole weight.2  Shell weight  Rings  \n",
       "0              0.1465        0.2400     11  \n",
       "1              0.2765        0.3200     11  \n",
       "2              0.0030        0.0050      6  \n",
       "3              0.2055        0.2500     10  \n",
       "4              0.1600        0.1975      9  \n",
       "...               ...           ...    ...  \n",
       "90610          0.0370        0.0450      6  \n",
       "90611          0.1815        0.2400      9  \n",
       "90612          0.0785        0.0815      6  \n",
       "90613          0.0490        0.0700      6  \n",
       "90614          0.0785        0.1050      8  \n",
       "\n",
       "[90615 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(CFG.path_train).drop('id', axis=1)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OH_transform(df_input):\n",
    "    df = df_input.copy()\n",
    "    for val in sorted(df['Sex'].unique()):\n",
    "        df[f'Sex_{val}'] = (df['Sex'] == val).astype(int)\n",
    "    df = df.drop('Sex', axis=1)\n",
    "    return df\n",
    "\n",
    "def label_transform(df_input):\n",
    "    df = df_input.copy()\n",
    "    mapper_sex = {'I':0, 'F':1, 'M':2}\n",
    "    df['Sex'] = df['Sex'].map(mapper_sex)\n",
    "    return df\n",
    "\n",
    "\n",
    "def preproc_data(df_input, scaler=None, df_original=None):\n",
    "    df = OH_transform(df_input)\n",
    "\n",
    "    if scaler is None:\n",
    "        scaler = StandardScaler()\n",
    "        data = scaler.fit_transform(df.drop(CFG.target, axis=1))\n",
    "        target = np.log1p(df[CFG.target]).values\n",
    "        return data, target, scaler\n",
    "    else:\n",
    "        return scaler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "cv_idx = [idx for idx in cv.split(df_train, df_train[CFG.target])]\n",
    "\n",
    "df_train = pd.read_csv(CFG.path_train).drop('id', axis=1)\n",
    "\n",
    "df_original = pd.read_csv(CFG.path_original)\n",
    "df_original = df_original.rename(columns={'Shucked weight': 'Whole weight.1', 'Viscera weight': 'Whole weight.2'})\n",
    "\n",
    "data, target, scaler = preproc_data(df_train)\n",
    "data_original = preproc_data(df_original.drop(CFG.target, axis=1), scaler)\n",
    "target_original = np.log1p(df_original[CFG.target]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuner = TabularNNTuner(data, target, cv_idx)\n",
    "# tuner.tune_parameters('NODE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in range(CFG.num_folds):\n",
    "\n",
    "    train_data = np.concatenate([data[cv_idx[fold][0]], data_original])\n",
    "    train_target = np.concatenate([target[cv_idx[fold][0]], target_original])\n",
    "    val_data = data[cv_idx[fold][1]]\n",
    "    val_target = target[cv_idx[fold][1]]\n",
    "\n",
    "    dataset_train = AbaloneDataset(train_data, train_target)\n",
    "    dataset_val = AbaloneDataset(val_data, val_target)\n",
    "\n",
    "    batch_size=2**5\n",
    "    loader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "    loader_val = DataLoader(dataset_val, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    DEVICE = torch.device('cuda')\n",
    "\n",
    "    experiments = (\n",
    "        # ('saint_8_8', SAINTModel, {'in_features': 10, 'hidden_dim': 8, 'num_attention_heads': 8, 'num_layers': 8, 'dropout': 0.2}),\n",
    "        ('ft_8_4', FTTransformerModel, {'in_features': 10, 'hidden_dim': 8, 'num_attention_heads': 8, 'num_layers': 4, 'dropout': 0.2}),\n",
    "        # ('tab_8_8', TabTransformerModel, {'in_features': 10, 'hidden_dim': 8, 'num_attention_heads': 8, 'num_layers': 8, 'dropout': 0.2}),\n",
    "    )\n",
    "\n",
    "    dir_save = 'nn_models'\n",
    "    for label, model_class, model_params in experiments:\n",
    "        print(f'{TXT_ACC} {label}    fold {fold} {TXT_RESET}')\n",
    "        scores, epochs, best_state = TabularNNTuner.score(\n",
    "                                            model_class, \n",
    "                                            model_params,\n",
    "                                            loader_train,\n",
    "                                            loader_val,\n",
    "                                            learning_rate=1e-3, \n",
    "                                            device=DEVICE,\n",
    "                                            verbose=True)\n",
    "        torch.save(best_state, f'{dir_save}/{label}_fold_{fold}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(CFG.path_test).drop('id', axis=1)\n",
    "\n",
    "test_data = preproc_data(df_test, scaler)\n",
    "\n",
    "dataset_test = AbaloneDataset(test_data)\n",
    "\n",
    "batch_size=2**5\n",
    "loader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for label, model_class, model_params in experiments:\n",
    "\n",
    "    preds_folds = []\n",
    "    for fold in range(CFG.num_folds):\n",
    "\n",
    "        train_data = np.concatenate([data[cv_idx[fold][0]], data_original])\n",
    "        train_target = np.concatenate([target[cv_idx[fold][0]], target_original])\n",
    "        val_data = data[cv_idx[fold][1]]\n",
    "        val_target = target[cv_idx[fold][1]]\n",
    "\n",
    "        dataset_train = AbaloneDataset(train_data, train_target)\n",
    "        dataset_val = AbaloneDataset(val_data, val_target)\n",
    "\n",
    "        batch_size=2**5\n",
    "        loader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "        loader_val = DataLoader(dataset_val, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        model = model_class(**model_params).to(DEVICE)\n",
    "        model.load_state_dict(torch.load(f'{dir_save}/{label}_fold_{fold}.pth'))\n",
    "        model.eval()\n",
    "\n",
    "        preds = []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in loader_val:\n",
    "                out = model(batch[0].to(DEVICE))\n",
    "                preds.extend(out.cpu().numpy())\n",
    "\n",
    "        preds_folds.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in range(CFG.num_folds):\n",
    "    df_sub = pd.DataFrame()\n",
    "    df_sub[CFG.target] = np.expm1(preds_folds[fold])\n",
    "    df_sub.to_csv(f'OOF_ft_8_4_fold{fold}.csv', index=False)\n",
    "    # display(df_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
